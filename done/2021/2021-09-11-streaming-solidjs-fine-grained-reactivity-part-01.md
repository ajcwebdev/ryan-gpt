---
showLink: "https://www.youtube.com/watch?v=b9e7VXs_A4s"
channel: "Ryan Carniato"
channelURL: "https://www.youtube.com/@ryansolid"
title: "Streaming SolidJS: Fine-Grained Reactivity"
description: ""
publishDate: "2021-09-11"
coverImage: "https://i.ytimg.com/vi/b9e7VXs_A4s/hqdefault.jpg?v=613bfece"
---

## Episode Description

Deep exploration of fine-grained reactivity, demonstrating how signals, derivations, and computations underpin SolidJS’s runtime and rendering mechanics.

## Episode Summary

In this two-hour livestream, Ryan Carniato methodically unpacks the concepts and implementations of fine-grained reactivity, using SolidJS and foundational JavaScript as guiding examples. He begins by defining reactivity as declarative programming that allows systems to update automatically based on defined rules. The discussion then shifts to primitive reactive constructs—signals, derivations (memos), and reactions—showing how various frameworks like Knockout, Vue, Solid, MobX, and React expose a common “signal” interface under different names. Carniato walks through building a minimal reactive core from scratch, illustrating how subscriptions, context stacks, and cleanup work together to propagate updates efficiently without glitches. He further demonstrates dynamic dependencies with computed values, compares runtime and compile-time reactivity, and highlights performance trade-offs between functions and proxies. Midway, he covers advanced topics like untracking contexts, batching updates, and ensuring glitch-free execution via topological ordering. In the latter half, Carniato delves into SolidJS-specific mechanisms—disposal via createRoot and onCleanup, nested roots for mapping arrays, universal props handling, and the “insert” and “spread” utilities that form a lightweight, high-performance renderer. Throughout, practical code demos and detailed explanations show how Solid streamlines reactivity into a cohesive system, culminating in a full-fledged render pipeline built atop these core concepts.

## Chapters

### 00:00:00 - Introduction to Fine-Grained Reactivity

At the very start of the stream, Ryan unpacks what “reactivity” means beyond buzzwords like spreadsheets or streams. He frames reactivity as choosing a declarative style of programming where developers describe relationships—“rules” that automatically drive updates—rather than manually wiring imperative logic. This perspective shift stems from challenges in tracking elaborate imperative update sequences in complex UIs. By embracing a declarative rule-based approach, you offload the burden of synchronization and let the reactive engine maintain consistency. He also contrasts the broad, systems-level view of reactivity—where one thinks in terms of data flow graphs—with the narrower perspective common in UI libraries, illustrating why reactivity feels different as projects grow in scale. In doing so, he sets the stage for demonstrating how frameworks like Solid capture these declarative principles at the “fine-grained” level.

Once the foundational “why” of reactivity is established, Ryan quickly reviews its historical roots in spreadsheets, digital circuit design, and hardware description languages. He explains that these earlier domains needed a way to synchronize changes without manually tracking every dependency, and that reactive primitives emerged to solve that. By referencing late-’60s spreadsheet concepts and hardware description patterns like VHDL, he shows that modern JavaScript frameworks stand on decades of research in synchronization. This discussion transitions into why we need more precise granularity in UIs compared to full re-renders—motivation for the “fine-grained reactivity” approach in Solid. Through this intro, viewers get clear context: reactivity is about declaring relationships once and letting the engine maintain up-to-date state, and this livestream will reveal how that happens under the hood.

### 00:05:00 - Core Primitives: Signals, Derivations, Reactions

Around the five-minute mark, Ryan zeroes in on the three essential primitives that drive any reactive system: signals (atomic state), derivations (computed or memoized values), and reactions (side-effectful code that executes when dependencies change). He showcases a concise code snippet illustrating how to create a “signal” across five frameworks—KnockoutJS, Vue 3, Solid, MobX, and React—emphasizing that, despite different syntax, they all expose a getter-setter mechanism to intercept reads and writes. In Knockout, signals are functions you call with no arguments to read and with one argument to write; Vue’s `ref` offers a `.value` property; Solid uses a React-like `[get, set]` tuple; MobX proxies an object with `.get`/.`set`; and React’s `useState` pairs a state variable with an updater function. Carniato emphasizes that, at the heart of each API, there’s a shared “language” of atomic state that underlies UIs, proving that signals aren’t unique to any one framework.

Continuing in this segment, he teases how derivations and reactions manifest in each library. Whether you call them “computed,” “watches,” “autotruns,” or “effects,” they all revolve around wrapping a callback function, tracking which signals it reads, and re-executing when any dependency changes. Ryan stresses that the key reason frameworks converge on this three-pronged model is to let developers write code naturally—imperative expressions for reading and updating signals—while the runtime handles subscription management behind the scenes. By the end of this section, viewers understand not just how to spot signals and reactions in code, but why these primitives collectively form a language that any reactive framework uses to build UIs from the ground up.

### 00:10:00 - Building a Minimal Reactive System: Signals & Subscriptions

At the ten-minute mark, Ryan begins building out a minimal reactive core in plain JavaScript to demystify how signals and their subscriptions actually work under the hood. He introduces a toy implementation where each signal holds a `Set` of subscribers (reactions) and a “context stack” tracks the current running effect. When you read from a signal inside a running reaction, it inspects the top of that stack to know which effect to subscribe—registering a two-way link so both the signal knows its subscribers and the effect knows which signals to unsubscribe from on cleanup. When you write to the signal, it clones its list of subscribers and re-runs each reaction, ensuring that changes cascade in a stable manner. Through this back-and-forth, Ryan illuminates how a signal acts like an event emitter and how the global context stack ties signals to the precise effect that reads them. This core example, though only a few dozen lines of JavaScript, already achieves the essential reactive mechanism: reading, subscribing, writing, and notifying in a synchronized loop.

Ryan illustrates why cloning subscribers on write is crucial: without cloning, a reaction could re-subscribe while its parent loop is iterating, leading to infinite loops. He also highlights the pull-based nature of fine-grained reactivity (i.e., you can always synchronously read a signal’s current value), distinguishing it from push-only streams like RxJS. By the end of this section, viewers see exactly how signals accumulate and manage subscriptions, how context swapping during reads tracks dynamic dependencies, and how simple JavaScript closures and `Set` operations form the bedrock of a reactive engine. The demonstration makes it clear that even though frameworks present “magic,” the underlying approach is just short JavaScript code tying closures to sets and stacks.

### 00:15:00 - Full Reactive System Implementation: Code Sandbox Demo

Around fifteen minutes in, Ryan switches to a shared screen and opens a CodeSandbox containing his complete 52-line reactive system. He encourages viewers to inspect this minimal implementation that fully supports dynamic dependencies, context tracking, cleanup, and effect execution. The `createSignal` function encapsulates a primitive value, a set of subscribers, and getter/setter logic; the `createEffect` function builds an object that stores its own dependency list along with an `execute` method that pushes itself onto the global context stack, runs the user-supplied callback, and then pops itself off. A `cleanup` method detaches the effect from any signals it previously subscribed to before re-running, ensuring that stale dependencies don’t linger. Ryan meticulously walks through each line of code, highlighting how the effect attaches to signals during reads, how the setter iterates over cloned subscribers, and how the overall “stack” mechanism orchestrates a stable reactive graph.

He then demonstrates a live example in the sandbox: a counter `count` signal and a `createEffect` that logs its value. Initially, when setting `count`, it immediately logs the new value. When reassigning, the effect re-runs correctly. Ryan pauses to explain that each re-execution cleans up old subscriptions so that only the latest dependencies matter, avoiding memory leaks or errant updates. This hands-on walkthrough cements the abstraction he described earlier: signals are value-holders tied to a global stack-driven, context-aware subscription system. By building a working reactive core from scratch, viewers gain a concrete sense of why frameworks like Solid, Vue, and MobX can “just work” with only minimal JavaScript underpinnings.

### 00:20:00 - Derivations & Memos: Dynamic Dependencies

At twenty minutes, the discussion moves to derivations—Solid’s `createMemo` or Vue/MobX’s “computed.” Ryan clarifies that while a naive approach could build a computed by simply wrapping a `createEffect` to reassign a downstream signal, true derivations excel at dynamic dependencies. He shows an example where a `showFullName` boolean signal controls whether `displayName` returns `firstName` alone or the concatenated `firstName + " " + lastName`. With a simple reactive system, one might write:

```
const displayName = computed(() => showFullName() ? firstName() + " " + lastName() : firstName());
createEffect(() => console.log(displayName()));
```

But if `displayName` is naively implemented as “run this effect and set a signal,” the reactive graph cannot skip re-running when irrelevant signals change. For instance, when `showFullName` is false, `lastName` updates should not trigger any recomputation. Ryan demonstrates how a proper `createMemo` built at runtime tracks only those signals actually read during a particular evaluation, attaching subscriptions dynamically. Consequently, when `showFullName` is false, `lastName` changes go unnoticed by `displayName`, saving unnecessary work and I/O.

He further emphasizes that dynamic dependencies enable fine-grained control over updates: instead of recomputing every branch every time, derivations pruned dependency graphs at runtime. This capability contrasts with compile-time models (like Svelte), which cannot anticipate which branch a conditional will take at runtime, leading them to conservatively update more than necessary. By the end of this segment, viewers appreciate that derivations/memos are not merely caching layers but essential mechanisms for skipping irrelevant updates and maintaining performance in complex reactive graphs.

### 00:25:00 - Computed Values vs Plain Functions: Performance Considerations

From twenty-five minutes onward, Ryan examines when to use computed/memos versus plain functions. A simple example shows that wrapping `displayName` in a memo only matters if its value is expensive to compute or frequently reused: concatenating two strings is trivial, so the overhead of creating and destroying a memo might outweigh its savings. He demonstrates that, in cases where a computed has no measurable side effects (and its dependencies run sequentially), you could replace it with a plain function:

```js
function displayName() {
  return showFullName() ? `${firstName()} ${lastName()}` : firstName();
}
```

and feed that into a single `createEffect`. The result is semantically identical—when neither `firstName` nor `showFullName` changes, no extra work is done. However, if `displayName` is accessed by multiple reactions, or if the string concatenation becomes burdensome, then a memo genuinely caches the intermediate result, preventing redundant computations. Ryan stresses that developer intuition often overuses `computed` simply because it’s available; instead, it should be reserved for cases where caching yields clear performance gains.

He then juxtaposes runtime dynamic derivations with compile-time reactive approaches, illustrating that compute-on-write in VDOM-based frameworks can sometimes force unnecessary re-evaluations. This segment also delves into how reacting to changes happens in Solid or Vue: if a computed node doesn’t actually change its value, it can early-exit and avoid notifying downstream dependencies. By understanding these trade-offs, viewers learn to apply computed/memos judiciously—employing them for intensive calculations or when values are consumed by multiple consumers, but skipping them for trivial one-off expressions. This balanced approach to memoization ensures reactive graphs remain both correct and optimal.

### 00:30:00 - Performance Deep Dive: Functions, Proxies & Benchmarks

Around the thirty-minute marker, Ryan broadens the discussion into real-world performance considerations, comparing functions versus proxies and examining current benchmark data. He notes that invoking a function to read a reactive value is roughly three times faster than using a proxy-based signal (e.g., MobX’s `observable`). Meanwhile, access via proxy is faster than intercepting with property getters/setters as in Vue’s `ref`. He uses the JS Framework Benchmark chart to show trends: React Hooks (functions) consistently outperform older class-based React, and libraries that rely on fine-grained functions often outpace those relying heavily on proxies or deep traps. These benchmarks demonstrate that the overhead of closures and context stacks can be negligible compared to the raw cost of DOM ops or large-scale diffing.

Ryan also addresses developer fears about closure creation in hooks. He reminds viewers that modern JS engines optimize ephemeral closures heavily: unless you store extensive state inside them, their creation cost is minimal compared to running complex UI updates. He cites examples where React Hooks performance improvements outpaced class-based approaches, debunking the myth that “too many closures” automatically slow down an app. By the end of this segment, viewers understand that while micro-optimizations matter, choosing an intuitive, function-first reactive API can yield surprisingly robust performance, and that the cost of dynamic dependency tracking is often dwarfed by downstream rendering work.

### 00:35:00 - Glitch-Free Execution & Dependency Graphs

At thirty-five minutes, Ryan turns to the challenge of ensuring “glitch-free” updates—where multi-source dependencies yield consistent intermediate states rather than flickering or incorrect values. He introduces the concept of dependency graphs and explains that naive update propagation (e.g., pushing new data down branches in arbitrary order) can cause temporary states where some computed values see new data while others still see old. To avoid this, a reactive system must first broadcast “I’m stale” to all downstream derivations, then traverse the graph in topologically consistent order, recomputing each node only after its dependencies have settled. He references a detailed MobX article by Michael West that enumerates a four-phase approach: sending stale notifications, awaiting readiness, re-evaluating derivations, and finally notifying reactive effects.

Ryan sketches a simplified dependency graph where two source signals (A and B) feed into a computed (C) that depends on B, and an effect depends on both A and C. When both A and B update simultaneously, the engine must mark `C` stale before running any effects. He highlights that if you simply recompute `A`’s branch first but let the effect read `C` before it’s recomputed, the logged result is inconsistent. Through this explanation, viewers learn why dynamic derivations matter: they let the reactive engine know exactly which nodes to update and when, ensuring that by the time the top-level effect runs, both A and B’s influence is fully incorporated. This ensures that the system never “glitches” or outputs a transient, incorrect value.

### 00:40:00 - Glitch-Free Example: Branching Signals and Ordering

At the forty-minute point, Ryan demonstrates a concrete example to illustrate glitch-free ordering. He creates two signals `A = 2` and `B = 3`, a computed `C = B * 2`, and an effect that logs `A + C`. Initially, `C` computes as 6, so the effect logs 2 + 6 = 8. When both `A` and `B` are set to new values—say 5 and 4 respectively—a naive system might recompute `A` first, then run the effect, reading `C = 6` (stale), printing 11, then recompute `C` before a second effect run, printing 13 again. In contrast, a glitch-free approach first marks `C` stale (since `B` changed), then recomputes `C` before the effect reads it, ensuring the final logged value is 5 + 8 = 13 once, rather than glimpsing 11 midstream. Ryan steps through each subscription list, showing how initial stale notifications cascade to dependent nodes, prompting them to recompute before re-notifying their downstream subscribers.

He further explores edge cases: what if `C`’s computation itself triggers another derived node? Ryan walks viewers through a hypothetical where a deeper derivation chain requires careful topological traversal. By analyzing how each signal and computed node holds lists of subscribers, and how each node tracks its own dependencies, he shows that the runtime can simply pause effect execution until all upstream stale signals have updated. This example demystifies why a reactive engine must “pull” new values in the correct order rather than “push” updates arbitrarily. The lesson: without this staging of stale/ready notifications, UI state can visibly glitch, but with proper notification graphs, a consistent final outcome is guaranteed.