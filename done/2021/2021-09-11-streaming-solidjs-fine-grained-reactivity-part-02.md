---
showLink: "https://www.youtube.com/watch?v=b9e7VXs_A4s"
channel: "Ryan Carniato"
channelURL: "https://www.youtube.com/@ryansolid"
title: "Streaming SolidJS: Fine-Grained Reactivity"
description: ""
publishDate: "2021-09-11"
coverImage: "https://i.ytimg.com/vi/b9e7VXs_A4s/hqdefault.jpg?v=613bfece"
---

## Episode Description

Deep exploration of fine-grained reactivity, demonstrating how signals, derivations, and computations underpin SolidJS’s runtime and rendering mechanics.

## Episode Summary

In this two-hour livestream, Ryan Carniato methodically unpacks the concepts and implementations of fine-grained reactivity, using SolidJS and foundational JavaScript as guiding examples. He begins by defining reactivity as declarative programming that allows systems to update automatically based on defined rules. The discussion then shifts to primitive reactive constructs—signals, derivations (memos), and reactions—showing how various frameworks like Knockout, Vue, Solid, MobX, and React expose a common “signal” interface under different names. Carniato walks through building a minimal reactive core from scratch, illustrating how subscriptions, context stacks, and cleanup work together to propagate updates efficiently without glitches. He further demonstrates dynamic dependencies with computed values, compares runtime and compile-time reactivity, and highlights performance trade-offs between functions and proxies. Midway, he covers advanced topics like untracking contexts, batching updates, and ensuring glitch-free execution via topological ordering. In the latter half, Carniato delves into SolidJS-specific mechanisms—disposal via createRoot and onCleanup, nested roots for mapping arrays, universal props handling, and the “insert” and “spread” utilities that form a lightweight, high-performance renderer. Throughout, practical code demos and detailed explanations show how Solid streamlines reactivity into a cohesive system, culminating in a full-fledged render pipeline built atop these core concepts.

## Chapters

### 00:45:00 - Demonstration of Notification & Execution Order

As the stream crosses the forty-five-minute mark, Ryan fires up the sandbox again and runs the glitch-free reactive example live. He modifies the source code to illustrate exactly how `setA(newA); setB(newB);` triggers notifications. First, both signals broadcast “stale” to their subscribers. Next, `C` sees `B` is stale and recomputes to the new value. Finally, the effect sees both `A` and `C` have settled and logs their sum once. Viewers watch the console output confirm this ordering: no intermediate or incorrect sums appear. Ryan then toggles the update order—setting `B` before `A`, or vice versa—and shows that the final output remains consistent, thanks to the system’s pre-notification strategy.

He also comments on how Solid’s actual implementation differs slightly: it schedules effects on a priority queue rather than running them immediately, which smooths out batch updates in UIs. However, the core idea remains identical: all stale derivations must recompute before any dependent reactions fire. By stepping through both code and console output, Ryan reinforces the intuition that a base reactive engine, complete with dynamic dependency tracking, stale notifications, and immediate recomputation, is enough to guarantee glitch-free UI updates. This live demonstration cements viewers’ understanding of what a robust reactive graph can achieve.

### 00:50:00 - Untracked & Batch: Synchronous Execution & Batching

At the fifty-minute mark, Ryan introduces two auxiliary utilities critical to real-world reactive systems: `untrack` and `batch`. He explains that in a fine-grained runtime, updates typically execute synchronously: when you call `signal.set()`, any subscribed effects run immediately before the next line of code executes. While this is essential for deterministic state, sometimes you want to group multiple signal updates into one unit of work—that’s where `batch` comes in. By wrapping multiple `set` calls inside `batch`, the runtime defers effect execution until after all updates complete. This grouping minimizes redundant effect runs and can dramatically improve performance, especially in scenarios where several interdependent signals change at once.

Conversely, `untrack` temporarily disables dependency tracking for a block of code. Ryan shows how it’s implemented by snapshotting the current context stack and clearing it before running a callback, then restoring it afterward. This prevents a read from a signal inside `untrack` from registering as a subscriber. While powerful, `untrack` can easily lead to stale state if misused—Ryan demos an example where a `showFullName` flag is untracked, causing `lastName` changes to go unnoticed when `showFullName` is false. His cautionary tale: only use `untrack` when you’re certain you don’t want a dependency, because skipping a subscription can leave parts of your UI permanently out of sync. By the end of this section, viewers understand how `batch` and `untrack` help manage synchronous execution and avoid unnecessary updates, yet also why they require careful handling.

### 00:55:00 - Untrack Implementation & Pitfalls

At minute fifty-five, Ryan deep-dives into the implementation details and pitfalls of `untrack`. He opens the sandbox and codes an `untracked` function by temporarily saving the global context stack, setting it to `null`, executing a callback, then restoring the old context. This illustrates the simplicity: untracked reads don’t notify any subscriber because there’s no “active” effect. He then wires this into a demo with `firstName`, `lastName`, and `showFullName` signals. When `showFullName` is toggled inside `untrack`, the computed value never re-subscribes to `showFullName`, causing future updates to `lastName` to be ignored—even when `showFullName` flips back to true. The result: the UI “freezes” with stale data, demonstrating why one wrong `untrack` can cascade into broken dependencies throughout the system.

Ryan reflects on historical pain points, recounting experiences where junior developers accidentally nested event callbacks inside reactive computations, causing runaway subscriptions, memory leaks, and infinite loops. He recalls a time in a legacy Knockout-based storefront where nested subscriptions triggered multiple back-and-forth updates across a two-way binding system, resulting in the UI constantly bouncing between values. These stories underscore his warning: while `untrack` is a neat mechanism, it breaks the guarantees of fine-grained reactivity if used loosely. He suggests relying on explicit dependencies—declaring which signals an effect truly needs—rather than ducking subscriptions with `untrack`. Thus, viewers leave this chapter with both a concrete `untrack` implementation and a healthy respect for its potential to introduce latent bugs.

### 01:00:00 - Batching & Scheduling in Reactive Systems

At the start of the second hour, Ryan reopens the broader topic of scheduling and batching in reactive libraries. Batching—combining multiple updates into one atomic step—avoids redundant work and prevents “ticking” the UI for each minor change. He contrasts Solid’s synchronous execution model with React’s microtask-based batching. In React, calling `setState` multiple times in the same event loop results in one render on the next microtask, leading to an implicit “batch.” Solid’s `batch`, however, explicitly delays effect execution until after all enclosed updates finish, yet still runs them synchronously before the next line of JavaScript. MobX uses a similar concept called “actions,” where grouping multiple observable mutations under an action defers all reactions until the action completes. This unified understanding of batching is crucial for developing predictable performance in complex apps.

Ryan then revisits dynamic dependency tracking to explain why scheduling and batching rely on knowing which derivations depend on which signals. If a library doesn’t track dependencies dynamically or can’t schedule effects precisely, it may re-run too much or too little. He underscores how Solid’s createEffect scheduling ensures that nested effects neither block the event loop nor produce unnecessary intermediate states. By the end of this chapter, viewers grasp that batching is not only about saving CPU cycles but also about maintaining UI consistency—deferring reactions until a stable set of updates is applied, thereby avoiding thrashing or stale reads. This careful orchestration between batching and dynamic graphs is what makes fine-grained reactivity feel instantaneous and glitch-free.

### 01:05:00 - Stale/Ready Notifications: MobX Insights

As the stream reaches the hour-five-minute mark, Ryan cites a detailed Hacker Noon article on MobX’s “fully reactive” engine by Michael West. He highlights how MobX implements a four-step protocol for each update: (1) propagate stale notifications downwards so every downstream derivation knows its inputs may change, (2) after collecting all stale signals, recompute derivations in topological order, (3) record which values actually changed, and (4) notify observers of only those derivations whose values differ. This approach ensures that computed values only re-evaluate when necessary and that effects trigger only once when all upstream dependencies settle. By comparing his minimal runtime to MobX’s production-grade implementation, Ryan demonstrates how adding “stale” markers and counting readiness messages yields robust, glitch-free updates even in deeply nested dependency trees.

He walks through a small dependency graph example: signal `A` and signal `B` feed into computed `C`. When `B` updates, MobX first marks `C` as stale before re-evaluating it. If `C`’s new value matches the old one, MobX halts propagation—no effects run. Otherwise, MobX sends a “ready” notification to `C`’s subscribers. Ryan stresses that this pre-notification mechanism distinguishes MobX (and systems like Solid) from naive reactivity: it’s the difference between an inconsistent intermediate UI state and a perfectly consistent final state. For viewers, these insights clarify why explicit “stale”/“ready” signaling matters in complex reactive graphs, ensuring that no reaction observes a partially updated set of dependencies.

### 01:10:00 - Untrack in Solid Components: Avoiding Unwanted Subscriptions

At seventy minutes, Ryan circles back to explain how Solid uses `untrack` internally to keep components from accidentally subscribing to signals they shouldn’t. When a component function renders JSX, Solid wraps each call site in an untracked context—ensuring that reading a prop inside a component doesn’t implicitly subscribe to it. Without `untrack`, destructuring props or accessing signal values during render would link parent components to child state, causing entire subtrees to re-render on any property access. He shows a hypothetical example: a parent signal `value` flows to a child component. If Solid didn’t wrap component invocations in `untrack`, simply destructuring `props.value` in the child would cause the parent’s reactive context to re-execute, leading to unexpected full app updates whenever that prop changed. By untracking at component boundaries, Solid isolates reactive subscriptions to precisely the computations that need them.

Ryan also points out that `untrack` is used to circumvent the default “closest subscriber” behavior when reading signals outside of effects. In Solid, the entire component tree is built from nested `createEffect` calls, but component functions themselves are untracked so any incidental signal reads (e.g., for conditional rendering) don’t bubble up and re-render entire branches. He clarifies that untracked contexts sit at known points—component boundaries and root initialization—providing a predictable structure where only intended subscriptions form. As a result, developers can write components that freely read signals without fear of creating unwanted reactive edges. This tight control over subscription scope is a core reason Solid achieves high performance and predictable reactivity in large component trees.

### 01:15:00 - Disposal & Roots: onCleanup & Memory Management

At the hour-fifteen mark, Ryan dives into how Solid manages memory and disposal through `onCleanup` and `createRoot`. He begins by recalling the 52-line reactive core: each effect keeps a list of dependencies (signals) it subscribes to and must clean those up on every re-run. In Solid, `onCleanup` lets you register a callback that runs whenever an effect is about to dispose—analogous to returning a cleanup function in React’s `useEffect`. He demonstrates this by adding `onCleanup` inside a computed that tracks `fullName`. Each time the computed re-runs with different dependencies, `onCleanup` removes the old subscriptions, preventing stale signals from lingering and generating memory leaks. He further notes that effects themselves are disposable scopes: when an effect’s parent scope re-runs or unmounts, Solid automatically cleans up all children, ensuring no orphaned subscriptions.

Ryan then explains `createRoot`, the primitive that establishes an untracked root context (no parent subscriptions) for your Solid app. When you call `createRoot`, Solid creates a root effect that owns the entire reactive tree under that root. When that root is disposed—e.g., when the app unmounts—Solid iterates over every nested effect and calls its cleanup, removing all subscriptions recursively. This design parallels React’s root “fiber,” but with explicit lifetime management. By wiring `onCleanup` callbacks into each effect and using `createRoot` to wrap component rendering, Solid guarantees that when a subtree is torn down (like in conditional rendering), all memory and subscriptions vanish. This chapter clarifies how Solid prevents memory leaks and ensures that every reactive node knows exactly when to release its resources.

### 01:20:00 - createRoot & Nested Roots: Mapping & Arrays in Solid

At eighty minutes, Ryan explores advanced disposal patterns involving nested roots and mapping over arrays. He points out that if you built a loop purely inside a parent effect—e.g., rendering a list of items—every time the parent effect re-ran, it would inadvertently dispose all child effects, even for items that remain present. To avoid such wholesale teardown, Solid wraps each iteration in its own `createRoot`, effectively isolating each item in the list. Each item root owns its own cleanup logic so that when an item is removed from the list, only that item’s root and its children are disposed—saving the rest of the list from unnecessary re-creation. Ryan shows a simplified `mapArray` implementation: for each new item, call `createRoot` with a callback that sets up that item’s DOM and subscriptions. If an item disappears, call the disposer for that root. This nested root strategy yields efficient list updates without tearing down the entire loop each time.

He underscores that roots inherently form a hierarchy: the top-level root spawns a child root for each component, which in turn can spawn child roots for nested loops or conditionals. Each root knows its parent, so disposing of a parent automatically cleans up all descendant roots. By using nested roots for loops, Solid achieves DOM reconciliation almost for free: existing child roots persist unchanged, newly added items get their own roots, and removed items get disposed without affecting siblings. This design elegantly handles dynamic lists, keyed updates, and component-level disposal, giving developers a robust pattern for mapping arrays and nested rendering. Viewers see how `createRoot` and nested roots collectively form a memory-safe backbone for Solid’s fine-grained reactivity.

### 01:25:00 - Components as Functions & Universal Props

At eighty-five minutes, Ryan reframes components as nothing more than functions that create reactive DOM fragments. He points out that if you let component functions run inside a reactive context, accidental signal reads during render can subscribe that component to signals it shouldn’t depend on. To maintain isolation, Solid treats every component invocation as a new untracked root—wrapping the function call in an untrack-like context so that any signal reads during initial render do not automatically cause subscriptions to bubble upward. This arrangement means that only the dynamic parts inside nested `createEffect` calls actually subscribe to signals. Ryan then illustrates how props, whether static or dynamic, can be passed uniformly: if a prop is a plain value, it’s treated as static; if it’s a function or an expression, the compiler wraps it in an accessor so that reading it becomes reactive. By adopting a “universal props” approach, Solid lets developers treat any prop as either static or signal-driven without rewriting code.

He demonstrates a child component receiving a `value` prop. If the parent passes `count` (a signal) directly, Solid’s compiler detects that `count` is a function call or member expression and thus generates code that wraps it in a getter: `() => props.value`. Inside the child, simply invoking `props.value()` correctly sets up a subscription to `count` without requiring the parent or child to explicitly handle signals. If instead the parent passes a literal (e.g., `3`), Solid recognizes it’s static and leaves it as a constant—skipping reactive wrapping. This universal prop pattern empowers developers to write components that seamlessly accept both static and dynamic inputs without boilerplate, making reactivity both ergonomic and robust.

### 01:30:00 - Universal Props in Solid: Compiler Optimizations

At ninety minutes, Ryan delves deeper into how Solid’s compiler optimizes universal props. He explains that the compiler uses simple syntactic checks—if a prop expression is a call expression, member expression, or tagged template, it treats it as dynamic, otherwise static. Dynamic props get compiled into accessor functions (e.g., `get foo() { return count(); }`), whereas static props become literal object properties. This early check allows Solid to avoid wrapping every prop in a signal or function at runtime, eliminating unnecessary overhead. Ryan shows a generated example: passing `user.name` becomes `() => props.user.name`, so every read sets up a dependency on `user.name` changes. But passing `{ id: 42 }` remains as a constant object, and no accessor is generated, saving allocation and subscription logic.

He also covers edge cases like spread props: when a component receives `{ ...props }`, Solid must iterate over each key-value pair and decide per-property whether to wrap it in an accessor or leave it static. The compiler emits a specialized `_spread` helper that performs these checks at runtime for each property in the object, batch-applying dynamic props as accessors and static ones as direct assignments. Through this compiler-driven interplay between static analysis and minimal runtime checks, Solid strikes a balance: nearly zero-cost static props and on-demand reactive wrapping for dynamic prop values. By the end of this segment, viewers understand that universal props are not just a conceptual convenience but an implementation that avoids needless subscriptions while preserving full reactivity for dynamic data.

### 01:35:00 - Building the Renderer: Insert & Spread Functions

At ninety-five minutes, Ryan tackles the final piece of Solid’s engine: the “insert” and “spread” utilities, which collectively form a minimal, high-performance renderer. He explains that while reactive primitives handle value updates, real-world UIs also require DOM insertion, removal, and attribute management. The `insert` function takes a parent node and a child value that might be a string, a DOM node, or a reactive function. If it’s a string, `insert` creates a text node or updates existing text; if it’s a DOM node, it replaces the old node; if it’s a function, `insert` wraps it in a nested effect so that any dynamic children update automatically. This approach lets Solid handle conditional fragments, lists, and text updates with a handful of lines of code, leveraging JavaScript’s native DOM APIs directly rather than a heavier virtual DOM.

Concurrently, the `spread` helper handles props and attributes on DOM elements. If you pass an object of attributes—some static, some reactive—`spread` iterates over each key-value pair. For static values, it does a direct `el.setAttribute(key, value)`; for dynamic values (functions or signals), it wraps that attribute update in an effect so that changes to the signal automatically call `setAttribute` again. By using `spread`, template authors can write an arbitrary `...props` expression, and Solid’s compiled output ensures that only dynamic attributes become subscriptions, while static ones remain one-off assignments. Through this dual approach—`insert` for children and `spread` for attributes—Ryan demonstrates how Solid’s renderer glues reactive primitives to DOM operations with minimal overhead, completing the engine needed to render any real application.

### 01:40:00 - Hyperscript Runtime: Insert & Spread Implementation

At the one-hour forty-minute mark, Ryan shifts to a hypothetical “Hyperscript” version of Solid’s runtime to show how an ultra-small rendering layer could work. Instead of JSX, you might write:

```js
const view = (props) => h("div", { class: props.active ? "active" : null }, [
  h("span", null, `Count: ${props.count()}`)
]);
```

He outlines how `h()` could internally call `insert` and `spread`: the first argument is the tag name, the second is the props object, and the third is an array of children, each of which could be a string, a DOM node, or a reactive function. By composing `h()` with `insert` for each child and `spread` for each attribute, you effectively replicate what JSX does in Solid. This simplified Hyperscript model makes transparent how little code is really needed—no Virtual DOM, no complex reconciliation algorithms—just a few dozen lines of logic linking reactive values to DOM mutations.

Ryan then demonstrates a live code snippet: a button whose label is a reactive signal, plus a dynamic class based on another signal. He shows how `spread` inspects the props object, wraps `class` in an effect because it’s a function, and leaves static `id` as a direct assignment. Meanwhile, `insert` creates a text node for the button’s label and sets up a nested effect so the label updates when its signal changes. Visually, it’s indistinguishable from a hand-written VDOM or JSX solution, yet it runs faster because there’s no intermediate tree diff. This chapter underlines that once you have reactive primitives, a minimal renderer is enough to manage all common UI tasks—text, elements, lists, and attributes—without additional frameworks.

### 01:45:00 - Completing the Runtime: Core Pieces & Templating

At one-hour forty-five, Ryan ties all the pieces together, emphasizing how fine-grained reactivity plus minimal rendering yields a full production-grade framework. He recaps: signals for atomic state, derivations for caching and dynamic dependencies, reactions for side effects, `batch` for grouping updates, `untrack` for scoping dependencies, `onCleanup` for proper disposal, nested roots for isolating loops, universal props for seamless prop handling, and finally `insert`/`spread` for applying changes to the DOM. When combined, these utilities form a cohesive engine where the compiler can generate straightforward JavaScript linking reactive data to real DOM operations. By compiling JSX (or Hyperscript) into calls that rely on `insert` and `spread`, Solid ensures that most of the work happens at compile time, minimizing runtime overhead.

He then briefly addresses how Solid’s compiler uses heuristics to detect where to insert `createMemo` wrappers for expensive computations (e.g., conditional fragments), further improving performance. Rather than relying on library authors to annotate every derived value manually, Solid’s template analyses automatically hoist dynamic calculations into memos when necessary. This built-in intelligence, combined with the simple reactive core, yields a framework that provides both developer ergonomics and performance. By the end of this section, viewers see the full picture: how to architect a high-performance, feature-complete UI framework using only fine-grained reactive primitives and a handful of helper functions.

### 01:50:00 - Final Summary & Wrap-Up

In the final five minutes, Ryan pauses to reflect on the entire content, acknowledging the two-hour deep dive and inviting questions from the community. He reiterates the three stages of his “article trilogy”: building a reactive system from scratch, extending it to a library renderer, and refining it into a robust framework like Solid. He encourages viewers to explore his written articles, which provide more polished code and diagrams, but highlights that everything shown in the stream is a direct implementation of those concepts. He also responds briefly to a chat question about disposal, pointing out that rooted contexts and automatic onCleanup calls form the backbone of Solid’s memory safety, and invites developers to experiment with nested roots for mapping arrays.

Finally, Ryan emphasizes that while the examples and demos focus on SolidJS, the principles apply to any fine-grained reactive library. By grasping how signals, derivations, and reactions work at a low level, developers can adapt these ideas to other contexts—custom view layers, UIs in non-Web environments, or even hardware simulations. He wraps up by thanking attendees for sticking through the long stream, promising future sessions to tackle scheduling nuances and other advanced topics. As the livestream ends, viewers are left with both a conceptual framework and concrete code to begin building reactive UIs that are efficient, scalable, and easy to reason about.